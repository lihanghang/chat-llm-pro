"""
åŸºäº Gradio è¿›è¡Œåº”ç”¨æ„å»º
é‡æ„ç‰ˆæœ¬ - ä½¿ç”¨æ¨¡å—åŒ–æ¶æ„
"""
import logging
import os
import shutil
import sys
from pathlib import Path

import gradio as gr

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ° Python è·¯å¾„
project_root = Path(__file__).resolve().parents[2]
if str(project_root) not in sys.path:
    sys.path.insert(0, str(project_root))

from web import host, port

# å¯¼å…¥è‡ªå®šä¹‰æ¨¡å—
from web.v2.components.chat_interface import ChatInterface
from web.v2.components.knowledge_tab import KnowledgeTab
from web.v2.services.chat_service import ChatService
from web.v2.services.file_service import FileService
from web.v2.services.model_manager import ModelManager
from web.v2.utils.error_handler import handle_errors


class ChatLLMApp:
    """ChatLLM åº”ç”¨ä¸»ç±»"""
    
    def __init__(self):
        """åˆå§‹åŒ–åº”ç”¨"""
        self.model_manager = ModelManager()
        self.file_service = FileService()
        self.chat_service = ChatService(self.model_manager, self.file_service)
        
        # åˆå§‹åŒ–ç»„ä»¶
        self.chat_interface = ChatInterface(self.chat_service, self.file_service)
        self.knowledge_tab = KnowledgeTab(self.chat_service)
    
    @handle_errors
    def init_store_dir(self, store_dir: str) -> None:
        """
        åˆå§‹åŒ–å­˜å‚¨ç›®å½•
        Args:
            store_dir: å­˜å‚¨ç›®å½•è·¯å¾„
        """
        if not os.path.exists(store_dir):
            os.makedirs(store_dir, exist_ok=True)
            logging.info(f"åˆ›å»ºå­˜å‚¨ç›®å½•: {store_dir}")
            return
        
        # æ¸…ç†ç°æœ‰æ•°æ®
        for root, dirs, files in os.walk(store_dir):
            for item in dirs:
                dir_path = os.path.join(root, item)
                shutil.rmtree(dir_path)
        logging.info("æ¸…ç†å­˜å‚¨æ•°æ®å®Œæˆ")
    
    def create_app(self) -> gr.Blocks:
        """
        åˆ›å»º Gradio åº”ç”¨
        Returns:
            Gradio Blocks åº”ç”¨å®ä¾‹
        """
        # è‡ªå®šä¹‰ CSS æ ·å¼
        custom_css = """
        footer {visibility: hidden}
        .markdown-body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', sans-serif;
            line-height: 1.6;
        }
        .markdown-body h1, .markdown-body h2, .markdown-body h3 {
            border-bottom: 1px solid #eaecef;
            padding-bottom: 0.3em;
        }
        .markdown-body code {
            background-color: #f6f8fa;
            padding: 0.2em 0.4em;
            border-radius: 3px;
        }
        .gradio-container {
            max-width: 1200px;
            margin: 0 auto;
        }
        """
        
        with gr.Blocks(
            css=custom_css,
            title="ChatLLM Pro - å¤§è¯­è¨€æ¨¡å‹åº”ç”¨ä½“éªŒ",
            theme=gr.themes.Soft()
        ) as demo:
            
            # é¡µé¢æ ‡é¢˜
            gr.Markdown(
                "# ğŸ¤– ChatLLM Pro\n"
                "## å¤§è¯­è¨€æ¨¡å‹åº”ç”¨ä½“éªŒå¹³å°\n\n"
                "> ç”± MemFinLLM æä¾›æŠ€æœ¯æ”¯æŒ | "
                "[è”ç³»æˆ‘ä»¬](https://www.memect.cn/)"
            )
            
            # åˆ›å»ºæ ‡ç­¾é¡µ
            with gr.Tabs():
                # åœºæ™¯é—®ç­”æ ‡ç­¾é¡µ
                self.chat_interface.create_scenario_qa_tab()
                
                # æ–‡æ¡£é—®ç­”æ ‡ç­¾é¡µ
                self.chat_interface.create_doc_qa_tab()
                
                # çŸ¥è¯†ç®¡ç†æ ‡ç­¾é¡µ
                self.knowledge_tab.create_knowledge_tab()
            
            # é¡µè„šä¿¡æ¯
            gr.Markdown(
                "---\n"
                "**ChatLLM Pro** - è®© AI å¯¹è¯æ›´ç®€å•ã€æ›´æ™ºèƒ½\n\n"
                "æ”¯æŒå¤šç§æ¨¡å‹ï¼šMemectFinLLMã€OpenAI GPTã€Azure OpenAI"
            )
        
        return demo
    
    def run(self) -> None:
        """è¿è¡Œåº”ç”¨"""
        try:
            # åˆå§‹åŒ–å­˜å‚¨ç›®å½•
            self.init_store_dir("data/store")
            
            # åˆ›å»ºåº”ç”¨
            demo = self.create_app()
            
            # å¯åŠ¨åº”ç”¨
            print(f"ğŸš€ å¯åŠ¨åº”ç”¨: http://{host}:{port}")
            demo.launch(
                server_name=host,
                server_port=int(port),
                share=True,
                show_error=True,
                quiet=False
            )
            
        except Exception as e:
            logging.error(f"åº”ç”¨å¯åŠ¨å¤±è´¥: {str(e)}")
            print(f"âŒ åº”ç”¨å¯åŠ¨å¤±è´¥: {str(e)}")
            raise


def main():
    """ä¸»å‡½æ•°"""
    # é…ç½®æ—¥å¿—
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
    )
    
    # åˆ›å»ºå¹¶è¿è¡Œåº”ç”¨
    app = ChatLLMApp()
    app.run()


if __name__ == "__main__":
    main()
